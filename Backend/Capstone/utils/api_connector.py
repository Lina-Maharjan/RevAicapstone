import requests
import re
from typing import List
from config.settings import settings
import logging

logger = logging.getLogger(__name__)

def extract_asin_from_url(url: str) -> str:
    """Extract ASIN from Amazon URL"""
    patterns = [
        r"/dp/([A-Z0-9]{10})",
        r"/gp/product/([A-Z0-9]{10})",
        r"asin=([A-Z0-9]{10})",
        r"/product/([A-Z0-9]{10})"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    raise ValueError("Invalid Amazon URL. Could not extract ASIN.")

def fetch_reviews_from_amazon(asin: str, max_pages: int = 3) -> List[str]:
    """Fetch reviews from Amazon using RapidAPI - Fixed to handle actual API response format"""
    all_reviews = []
    
    for page in range(1, max_pages + 1):
        # Using the exact URL format from your RapidAPI code
        url = "https://amazon-product-reviews1.p.rapidapi.com/amazonreviews/"
        
        querystring = {
            "asin": asin,
            "domain": "amazon.com", 
            "pageNum": str(page)
        }
        
        # Using the exact header format from your RapidAPI code
        headers = {
            "x-rapidapi-key": settings.RAPIDAPI_KEY,
            "x-rapidapi-host": settings.RAPIDAPI_HOST
        }
        
        try:
            logger.info(f"ðŸ” Fetching page {page} for ASIN: {asin}")
            response = requests.get(url, headers=headers, params=querystring, timeout=15)
            logger.info(f"ðŸ“Š API Response Status for page {page}: {response.status_code}")
            
            if response.status_code == 200:
                try:
                    json_data = response.json()
                    logger.info(f"ðŸ“¨ Response keys: {list(json_data.keys()) if isinstance(json_data, dict) else 'Not a dictionary'}")
                    
                    # Extract reviews from the response
                    page_reviews = []
                    
                    # Handle the actual API response structure
                    if isinstance(json_data, dict):
                        # The actual API returns: {"ProductName": "", "ProductRating": "", "Reviewers": [], ...}
                        reviewers = json_data.get("Reviewers", [])
                        logger.info(f"Found {len(reviewers)} reviewers in response")
                        
                        if reviewers and isinstance(reviewers, list):
                            for reviewer_data in reviewers:
                                if isinstance(reviewer_data, dict):
                                    # Extract review text from different possible fields
                                    review_text = None
                                    
                                    # Try different possible field names for review text
                                    for field in ["Review", "review", "ReviewText", "text", "comment", "ReviewContent"]:
                                        if field in reviewer_data and reviewer_data[field]:
                                            review_text = str(reviewer_data[field]).strip()
                                            break
                                    
                                    # If no review text found, try combining title and content
                                    if not review_text and "ReviewTitle" in reviewer_data and "ReviewContent" in reviewer_data:
                                        title = reviewer_data.get("ReviewTitle", "")
                                        content = reviewer_data.get("ReviewContent", "")
                                        if title or content:
                                            review_text = f"{title} {content}".strip()
                                    
                                    if review_text and len(review_text) > 10:
                                        page_reviews.append(review_text)
                                        logger.info(f"Added review: {review_text[:30]}...")
                    
                    all_reviews.extend(page_reviews)
                    logger.info(f"âœ… Found {len(page_reviews)} reviews on page {page}")
                    
                    # If no reviews found on this page, stop fetching
                    if not page_reviews:
                        logger.info(f"ðŸ›‘ No more reviews found, stopping at page {page}")
                        break
                        
                except Exception as e:
                    logger.error(f"âŒ Failed to parse JSON for page {page}: {str(e)}")
                    logger.error(f"Raw response preview: {str(response.text)[:300]}...")
                    break
                    
            elif response.status_code == 429:
                logger.warning(f"â° Rate limit hit for page {page}")
                break
                
            else:
                logger.error(f"âŒ API request failed for page {page} with status: {response.status_code}")
                logger.error(f"Response preview: {str(response.text)[:300]}...")
                break
                
        except requests.RequestException as e:
            logger.error(f"ðŸŒ Network error for page {page}: {str(e)}")
            break
        except Exception as e:
            logger.error(f"ðŸ’¥ Unexpected error for page {page}: {str(e)}")
            break
    
    logger.info(f"ðŸŽ¯ Total reviews fetched: {len(all_reviews)}")
    
    # If no reviews were fetched from API, return sample reviews for testing
    if not all_reviews:
        logger.warning("âš ï¸ No reviews found from API, using sample reviews")
        sample_reviews = [
            "This product is amazing! Great quality and fast shipping. Highly recommend!",
            "Not bad, but could be better. The quality is okay for the price.",
            "Terrible product! Broke after one day. Would not recommend to anyone.",
            "Excellent value for money. Exactly what I was looking for.",
            "Average product. Nothing special but does the job.",
            "The delivery was super quick but the product quality was disappointing.",
            "I've bought this product three times now. Always consistent quality.",
            "Overpriced for what it is. You can find better alternatives for less.",
            "The customer service was excellent when I had issues with my order.",
            "Beautiful design, but functionality could be improved."
        ]
        return sample_reviews
    
    # Remove duplicates while preserving order
    unique_reviews = []
    seen = set()
    for review in all_reviews:
        if review not in seen:
            unique_reviews.append(review)
            seen.add(review)
    
    logger.info(f"ðŸ”„ Unique reviews after deduplication: {len(unique_reviews)}")
    
    # Limit to 50 reviews to avoid overwhelming the system
    final_reviews = unique_reviews[:50]
    logger.info(f"ðŸ“ Final reviews returned: {len(final_reviews)}")
    
    return final_reviews

def test_api_connection(asin: str = "B01H6GUCCQ") -> dict:
    """Test API connection with a known ASIN"""
    try:
        url = "https://amazon-product-reviews1.p.rapidapi.com/amazonreviews/"
        querystring = {"asin": asin, "domain": "amazon.com", "pageNum": "1"}
        headers = {
            "x-rapidapi-key": settings.RAPIDAPI_KEY,
            "x-rapidapi-host": settings.RAPIDAPI_HOST
        }
        
        logger.debug(f"API Key: {settings.RAPIDAPI_KEY[:5]}...{settings.RAPIDAPI_KEY[-5:] if settings.RAPIDAPI_KEY else 'None'}")
        logger.debug(f"API Host: {settings.RAPIDAPI_HOST}")
        logger.debug(f"Testing API with ASIN: {asin}")
        
        response = requests.get(url, headers=headers, params=querystring, timeout=15)
        
        result = {
            "success": response.status_code == 200,
            "status_code": response.status_code,
            "response_preview": str(response.text)[:500] + "..." if len(response.text) > 500 else response.text
        }
        
        if response.status_code == 200:
            try:
                json_data = response.json()
                # Log the structure of the response
                result["response_keys"] = list(json_data.keys()) if isinstance(json_data, dict) else "Not a dictionary"
                if isinstance(json_data, dict) and "Reviewers" in json_data:
                    result["reviewers_count"] = len(json_data["Reviewers"])
                    result["product_name"] = json_data.get("ProductName", "N/A")
            except Exception as parse_error:
                result["parse_error"] = str(parse_error)
                
        return result
        
    except Exception as e:
        logger.error(f"API connection error: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }